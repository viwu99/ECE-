{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Victor Papin - Data & IA - TD 2\n",
    "# Exercise: Implementing Matrix Factorization from Scratch\n",
    "\n",
    "**Course:** Recommender Systems <br>\n",
    "**Professor:** Guilherme MEDEIROS MACHADO <br>\n",
    "**Topic:** Collaborative Filtering with Matrix Factorization\n",
    "\n",
    "---\n",
    "\n",
    "## Goal of the Exercise\n",
    "\n",
    "The objective of this exercise is to build a movie recommender system by implementing the **Matrix Factorization** algorithm from scratch using Python. We will use the famous **MovieLens 100k** dataset. By the end of this notebook, you will have:\n",
    "\n",
    "1.  Understood the theoretical foundations of matrix factorization.\n",
    "2.  Implemented the algorithm using **Stochastic Gradient Descent (SGD)**.\n",
    "3.  Trained your model on real-world movie rating data.\n",
    "4.  Evaluated your model's performance using Root Mean Squared Error (RMSE).\n",
    "5.  Generated personalized top-10 movie recommendations for a specific user.\n",
    "\n",
    "This exercise forbids the use of pre-built matrix factorization libraries (like `surprise`, `lightfm`, etc.) to ensure you gain a deep understanding of the inner workings of the algorithm.\n",
    "\n",
    "---\n",
    "\n",
    "## The Dataset: MovieLens 100k\n",
    "\n",
    "We will be using the MovieLens 100k dataset, a classic dataset in the recommender systems community. It contains:\n",
    "* 100,000 ratings (1-5) from...\n",
    "* 943 users on...\n",
    "* 1682 movies.\n",
    "\n",
    "You will need two files from this dataset:\n",
    "* `u.data`: The full dataset of 100k ratings. Each row is in the format: `user_id`, `item_id`, `rating`, `timestamp`.\n",
    "* `u.item`: Information about the movies (items). Each row contains the `item_id`, `movie_title`, and other metadata. We'll use it to get the movie names for our final recommendations.\n",
    "\n",
    "Let's start by downloading and exploring the data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T20:36:44.319223Z",
     "start_time": "2025-09-27T20:36:44.283223Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "\n",
    "from polars.selectors import alpha\n",
    "\n",
    "# --- Download the dataset if it doesn't exist ---\n",
    "if not os.path.exists('ml-100k'):\n",
    "    print(\"Downloading MovieLens 100k dataset...\")\n",
    "    url = 'http://files.grouplens.org/datasets/movielens/ml-100k.zip'\n",
    "    urlretrieve(url, 'ml-100k.zip')\n",
    "    with zipfile.ZipFile('ml-100k.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "    print(\"Download and extraction complete.\")\n",
    "\n",
    "# --- Load the data ---\n",
    "# u.data contains the ratings\n",
    "data_cols = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "ratings_df = pd.read_csv('ml-100k/u.data', sep='\\t', names=data_cols)\n",
    "\n",
    "# u.item contains movie titles\n",
    "item_cols = ['item_id', 'title'] + [f'col{i}' for i in range(22)] # Remaining columns are not needed\n",
    "movies_df = pd.read_csv('ml-100k/u.item', sep='|', names=item_cols, encoding='latin-1', usecols=['item_id', 'title'])\n",
    "\n",
    "# Merge the two dataframes to have movie titles and ratings in one place\n",
    "df = pd.merge(ratings_df, movies_df, on='item_id')\n",
    "\n",
    "print(\"Data loaded successfully!\")\n",
    "df.info()\n",
    "df.info()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   user_id    100000 non-null  int64 \n",
      " 1   item_id    100000 non-null  int64 \n",
      " 2   rating     100000 non-null  int64 \n",
      " 3   timestamp  100000 non-null  int64 \n",
      " 4   title      100000 non-null  object\n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   user_id    100000 non-null  int64 \n",
      " 1   item_id    100000 non-null  int64 \n",
      " 2   rating     100000 non-null  int64 \n",
      " 3   timestamp  100000 non-null  int64 \n",
      " 4   title      100000 non-null  object\n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "execution_count": 438
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Data Preparation\n",
    "\n",
    "The raw data is a list of ratings. For matrix factorization, it's conceptually easier to think of our data as a large **user-item interaction matrix**, let's call it $R$. In this matrix:\n",
    "* The rows represent users.\n",
    "* The columns represent movies (items).\n",
    "* The value at cell $(u, i)$, denoted $R_{ui}$, is the rating user $u$ gave to movie $i$.\n",
    "\n",
    "This matrix is typically very **sparse**, as most users have only rated a small fraction of the available movies.\n",
    "\n",
    "Let's create this matrix using a Pandas pivot table. This will also help us determine the number of unique users and movies."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T20:36:44.324878Z",
     "start_time": "2025-09-27T20:36:44.321736Z"
    }
   },
   "source": [
    "def create_user_item_matrix(df):\n",
    "    \"\"\"\n",
    "    Creates the user-item interaction matrix from the dataframe.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe containing user_id, item_id, and rating.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A user-item matrix with users as rows, items as columns, and ratings as values.\n",
    "                       NaNs indicate that a user has not rated an item.\n",
    "    \"\"\"\n",
    "    # TODO: Create a pivot table.\n",
    "    df_result = df.pivot(columns = 'item_id',index='user_id', values='rating')\n",
    "    return df_result\n",
    "    # The index should be 'user_id', columns 'item_id', and values 'rating'."
   ],
   "outputs": [],
   "execution_count": 439
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: The Theory of Matrix Factorization\n",
    "\n",
    "The core idea is to **decompose** our large, sparse user-item matrix $R$ (size $m \\times n$) into two smaller, dense matrices:\n",
    "1.  A **user-feature matrix** $P$ (size $m \\times k$).\n",
    "2.  An **item-feature matrix** $Q$ (size $n \\times k$).\n",
    "\n",
    "Here, $k$ is the number of **latent factors**, which is a hyperparameter we choose. These latent factors represent hidden characteristics of users and items. For movies, a factor might represent the \"amount of comedy\" vs. \"drama\", or \"blockbuster\" vs. \"indie film\". For users, a factor might represent their preference for these characteristics.\n",
    "\n",
    "\n",
    "\n",
    "The prediction of a rating $\\hat{r}_{ui}$ that user $u$ would give to item $i$ is calculated by the dot product of the user's latent vector $p_u$ and the item's latent vector $q_i$:\n",
    "\n",
    "$$\\hat{r}_{ui} = p_u \\cdot q_i^T = \\sum_{k=1}^{K} p_{uk} q_{ik}$$\n",
    "\n",
    "Our goal is to find the matrices $P$ and $Q$ such that their product $P \\cdot Q^T$ is as close as possible to the known ratings in our original matrix $R$. We formalize this using a **loss function**. A common choice is the sum of squared errors, with **regularization** to prevent overfitting:\n",
    "\n",
    "$$L = \\sum_{(u,i) \\in \\mathcal{K}} (r_{ui} - \\hat{r}_{ui})^2 + \\lambda \\left( \\sum_{u} ||p_u||^2 + \\sum_{i} ||q_i||^2 \\right)$$\n",
    "\n",
    "Where:\n",
    "* $\\mathcal{K}$ is the set of $(u, i)$ pairs for which the rating $r_{ui}$ is known.\n",
    "* $\\lambda$ is the regularization parameter, another hyperparameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: The Algorithm - Stochastic Gradient Descent (SGD)\n",
    "\n",
    "To minimize our loss function $L$, we will use **Stochastic Gradient Descent (SGD)**. Instead of calculating the gradient over all known ratings (which is computationally expensive), SGD iterates through each known rating one by one and updates the parameters in the direction that minimizes the error for that single rating.\n",
    "\n",
    "For each known rating $r_{ui}$:\n",
    "1.  Calculate the prediction error: $e_{ui} = r_{ui} - \\hat{r}_{ui}$\n",
    "2.  Update the user and item latent vectors ($p_u$ and $q_i$) using the following update rules:\n",
    "\n",
    "$$p_u \\leftarrow p_u + \\alpha \\cdot (e_{ui} \\cdot q_i - \\lambda \\cdot p_u)$$\n",
    "$$q_i \\leftarrow q_i + \\alpha \\cdot (e_{ui} \\cdot p_u - \\lambda \\cdot q_i)$$\n",
    "\n",
    "Where:\n",
    "* $\\alpha$ is the **learning rate**, a hyperparameter that controls the step size.\n",
    "\n",
    "We repeat this process for a fixed number of **epochs** (iterations over the entire training dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Step-by-Step Implementation\n",
    "\n",
    "Let's build our model. First, we need to split our data into a training and a testing set."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T20:36:44.397207Z",
     "start_time": "2025-09-27T20:36:44.346240Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df.sample(frac=1).reset_index(drop=True), test_size=0.2)\n",
    "dataset = create_user_item_matrix(df)\n",
    "\n",
    "R_train = create_user_item_matrix(df_train).to_numpy()\n",
    "R_test = create_user_item_matrix(df_test).to_numpy()\n",
    "\n",
    "\n",
    "# I could have done this without sklearn but I do think it's not the objective of this course so it's OK\n",
    "# To have 20% of the data I've first split the dataset THEN create the sparse matrice\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 440
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Initialization\n",
    "\n",
    "We need to initialize our user-feature matrix $P$ and item-feature matrix $Q$ with small random values."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T20:36:44.404236Z",
     "start_time": "2025-09-27T20:36:44.400213Z"
    }
   },
   "source": [
    "def initialize_matrices(n_users, n_items, n_factors):\n",
    "    \"\"\"\n",
    "    Initializes the user-feature (P) and item-feature (Q) matrices.\n",
    "\n",
    "    Args:\n",
    "        n_users (int): Number of users.\n",
    "        n_items (int): Number of items.\n",
    "        n_factors (int): Number of latent factors.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - P (np.ndarray): The user-feature matrix (n_users x n_factors).\n",
    "            - Q (np.ndarray): The item-feature matrix (n_items x n_factors).\n",
    "    \"\"\"\n",
    "    # TODO: Initialize P and Q with small random values from a standard normal distribution.\n",
    "\n",
    "    P = np.random.standard_normal(size=(n_users, n_factors)) * 0.0101\n",
    "    Q = np.random.standard_normal(size=(n_items, n_factors)) * 0.0101\n",
    "    return P, Q"
   ],
   "outputs": [],
   "execution_count": 441
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 The Training Loop (SGD)\n",
    "\n",
    "This is the core of our algorithm. We will loop for a specified number of epochs. In each epoch, we will iterate over all known ratings in our training set `R_train` and update the corresponding user and item vectors in `P` and `Q`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T20:36:44.419441Z",
     "start_time": "2025-09-27T20:36:44.414436Z"
    }
   },
   "source": [
    "def train_model(R_train, P, Q, learning_rate, regularization, epochs):\n",
    "    \"\"\"\n",
    "    Trains the matrix factorization model using SGD.\n",
    "\n",
    "    Args:\n",
    "        R_train (np.ndarray): The training user-item matrix.\n",
    "        P (np.ndarray): The user-feature matrix.\n",
    "        Q (np.ndarray): The item-feature matrix.\n",
    "        learning_rate (float): The learning rate (alpha).\n",
    "        regularization (float): The regularization parameter (lambda).\n",
    "        epochs (int): The number of iterations over the training data.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the trained P and Q matrices.\n",
    "    \"\"\"\n",
    "\n",
    "    nb_users, nb_items = R_train.shape\n",
    "    E = np.zeros_like(R_train)\n",
    "    rmse_old = 10\n",
    "    for epoch in range(epochs):\n",
    "        for u in range(nb_users):\n",
    "            for i in range(nb_items):\n",
    "                if R_train[u, i] > 0:\n",
    "                    # erreur\n",
    "                    E[u, i] = R_train[u, i] - P[u, :] @ Q[i, :].T\n",
    "\n",
    "                    p = P[u, :].copy(); q = Q[i, :].copy()\n",
    "                    P[u, :] += learning_rate * (E[u, i] * q - regularization * p)\n",
    "                    Q[i, :] += learning_rate * (E[u, i] * p - regularization * q)\n",
    "\n",
    "                    \"\"\"P[u, :] += learning_rate * (E[u, i] * Q[i, :] - regularization * P[u, :])\n",
    "                    Q[i, :] += learning_rate * (E[u, i] * P[u, :] - regularization * Q[i, :])\"\"\"\n",
    "\n",
    "        R_exp = P @ Q.T\n",
    "        E = R_train - R_exp\n",
    "        print(epoch, '/', epochs)\n",
    "        rmse = calculate_rmse(R_test,  P, Q)\n",
    "        print(\"\\n\", rmse, \"\\n\", rmse_old - rmse, \"\\n\", learning_rate)\n",
    "\n",
    "        if float(rmse_old - rmse) < 0.001 and learning_rate > 0.005:\n",
    "            learning_rate *= 0.9\n",
    "        rmse_old = rmse\n",
    "    return P, Q, E\n"
   ],
   "outputs": [],
   "execution_count": 442
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Evaluation\n",
    "\n",
    "After training, we must evaluate how well our model performs on unseen data. We will use the **Root Mean Squared Error (RMSE)**, which measures the average magnitude of the errors between predicted and actual ratings.\n",
    "\n",
    "The formula is:\n",
    "$$RMSE = \\sqrt{\\frac{1}{|\\mathcal{T}|} \\sum_{(u,i) \\in \\mathcal{T}} (r_{ui} - \\hat{r}_{ui})^2}$$\n",
    "\n",
    "Where $\\mathcal{T}$ is the set of ratings in our test set. A lower RMSE means better performance."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T20:36:44.433996Z",
     "start_time": "2025-09-27T20:36:44.430038Z"
    }
   },
   "source": [
    "def calculate_rmse(R_test, P, Q):\n",
    "    \"\"\"\n",
    "    Calculates the Root Mean Squared Error (RMSE) on the test set.\n",
    "\n",
    "    Args:\n",
    "        R_test (np.ndarray): The testing user-item matrix.\n",
    "        P (np.ndarray): The trained user-feature matrix.\n",
    "        Q (np.ndarray): The trained item-feature matrix.\n",
    "\n",
    "    Returns:\n",
    "        float: The RMSE value.\n",
    "    \"\"\"\n",
    "    nb = sum(\n",
    "        1\n",
    "        for u in range(R_test.shape[0])\n",
    "        for i in range(R_test.shape[1])\n",
    "        if R_test[u][i] > 0\n",
    "    )\n",
    "\n",
    "\n",
    "    sse = sum(\n",
    "            (R_test[u][i] - P[u, :] @ Q[i, :].T) ** 2\n",
    "            for u in range(R_test.shape[0])\n",
    "            for i in range(R_test.shape[1])\n",
    "            if R_test[u][i] > 0\n",
    "        )\n",
    "\n",
    "    return (sse / nb) ** 0.5"
   ],
   "outputs": [],
   "execution_count": 443
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6: Putting It All Together\n",
    "\n",
    "Now, let's connect all the pieces. We'll set our hyperparameters, initialize our matrices, train the model, and finally evaluate it.\n",
    "\n",
    "**Your Goal:** Tune the hyperparameters to achieve an **RMSE below 0.98**. A good model can even reach ~0.95. If your RMSE is higher, try adjusting the learning rate, regularization, number of factors, or epochs."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T20:36:44.453980Z",
     "start_time": "2025-09-27T20:36:44.445509Z"
    }
   },
   "cell_type": "code",
   "source": "df.info()",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   user_id    100000 non-null  int64 \n",
      " 1   item_id    100000 non-null  int64 \n",
      " 2   rating     100000 non-null  int64 \n",
      " 3   timestamp  100000 non-null  int64 \n",
      " 4   title      100000 non-null  object\n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "execution_count": 444
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T20:39:06.898017Z",
     "start_time": "2025-09-27T20:37:57.774695Z"
    }
   },
   "source": [
    "# --- Hyperparameters ---\n",
    "# Number of latent factors (k)\n",
    "# Learning rate (alpha)\n",
    "# Regularization parameter (lambda)\n",
    "# Number of epochs\n",
    "\n",
    "# --- Initialization ---\n",
    "# Remember user and item IDs are 1-based, but our numpy arrays are 0-based.\n",
    "# The number of users/items from the shape of R_df is correct for 0-based indexing.\n",
    "P, Q = initialize_matrices(n_users = R_train.shape[0], n_items= R_train.shape[1], n_factors=30)\n",
    "print(P.shape)\n",
    "print(Q.shape)\n",
    "# --- Training ---\n",
    "P, Q, E = train_model(R_train, P, Q, learning_rate=0.005, regularization=0.16, epochs=50)\n",
    "\n",
    "# --- Evaluation ---\n",
    "rmse = calculate_rmse(R_test,  P, Q)\n",
    "print(rmse)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 30)\n",
      "(1647, 30)\n",
      "0 / 70\n",
      "\n",
      " 3.699208942478729 \n",
      " 6.3007910575212716 \n",
      " 0.005\n",
      "1 / 70\n",
      "\n",
      " 3.621322766079138 \n",
      " 0.07788617639959083 \n",
      " 0.005\n",
      "2 / 70\n",
      "\n",
      " 2.629180205584836 \n",
      " 0.9921425604943019 \n",
      " 0.005\n",
      "3 / 70\n",
      "\n",
      " 1.948898540751616 \n",
      " 0.6802816648332202 \n",
      " 0.005\n",
      "4 / 70\n",
      "\n",
      " 1.651721656696268 \n",
      " 0.2971768840553479 \n",
      " 0.005\n",
      "5 / 70\n",
      "\n",
      " 1.4920911319810786 \n",
      " 0.15963052471518946 \n",
      " 0.005\n",
      "6 / 70\n",
      "\n",
      " 1.3994224570959677 \n",
      " 0.09266867488511088 \n",
      " 0.005\n",
      "7 / 70\n",
      "\n",
      " 1.3425189580628996 \n",
      " 0.05690349903306813 \n",
      " 0.005\n",
      "8 / 70\n",
      "\n",
      " 1.3058601138252064 \n",
      " 0.03665884423769317 \n",
      " 0.005\n",
      "9 / 70\n",
      "\n",
      " 1.2812027378661144 \n",
      " 0.02465737595909201 \n",
      " 0.005\n",
      "10 / 70\n",
      "\n",
      " 1.263953115656623 \n",
      " 0.017249622209491333 \n",
      " 0.005\n",
      "11 / 70\n",
      "\n",
      " 1.2514466804381368 \n",
      " 0.012506435218486267 \n",
      " 0.005\n",
      "12 / 70\n",
      "\n",
      " 1.2420820441407525 \n",
      " 0.009364636297384266 \n",
      " 0.005\n",
      "13 / 70\n",
      "\n",
      " 1.2348650709963884 \n",
      " 0.007216973144364092 \n",
      " 0.005\n",
      "14 / 70\n",
      "\n",
      " 1.2291597937725631 \n",
      " 0.0057052772238253 \n",
      " 0.005\n",
      "15 / 70\n",
      "\n",
      " 1.224547838313152 \n",
      " 0.004611955459411066 \n",
      " 0.005\n",
      "16 / 70\n",
      "\n",
      " 1.2207466983664619 \n",
      " 0.0038011399466901796 \n",
      " 0.005\n",
      "17 / 70\n",
      "\n",
      " 1.2175608978978865 \n",
      " 0.003185800468575417 \n",
      " 0.005\n",
      "18 / 70\n",
      "\n",
      " 1.2148520481961051 \n",
      " 0.002708849701781313 \n",
      " 0.005\n",
      "19 / 70\n",
      "\n",
      " 1.212520045825943 \n",
      " 0.0023320023701620674 \n",
      " 0.005\n",
      "20 / 70\n",
      "\n",
      " 1.2104910012643058 \n",
      " 0.0020290445616373276 \n",
      " 0.005\n",
      "21 / 70\n",
      "\n",
      " 1.208709327382801 \n",
      " 0.0017816738815048527 \n",
      " 0.005\n",
      "22 / 70\n",
      "\n",
      " 1.2071324538973784 \n",
      " 0.0015768734854224586 \n",
      " 0.005\n",
      "23 / 70\n",
      "\n",
      " 1.205727232382461 \n",
      " 0.0014052215149173986 \n",
      " 0.005\n",
      "24 / 70\n",
      "\n",
      " 1.2044674496593941 \n",
      " 0.0012597827230669267 \n",
      " 0.005\n",
      "25 / 70\n",
      "\n",
      " 1.2033320802904153 \n",
      " 0.0011353693689788447 \n",
      " 0.005\n",
      "26 / 70\n",
      "\n",
      " 1.2023040398396618 \n",
      " 0.0010280404507534424 \n",
      " 0.005\n",
      "27 / 70\n",
      "\n",
      " 1.2013692825862965 \n",
      " 0.000934757253365337 \n",
      " 0.005\n",
      "28 / 70\n",
      "\n",
      " 1.2005161396512236 \n",
      " 0.0008531429350728814 \n",
      " 0.005\n",
      "29 / 70\n",
      "\n",
      " 1.1997348273518802 \n",
      " 0.0007813122993434174 \n",
      " 0.005\n",
      "30 / 70\n",
      "\n",
      " 1.1990170778436688 \n",
      " 0.0007177495082113516 \n",
      " 0.005\n",
      "31 / 70\n",
      "\n",
      " 1.1983558589187067 \n",
      " 0.0006612189249621814 \n",
      " 0.005\n",
      "32 / 70\n",
      "\n",
      " 1.197745159810217 \n",
      " 0.000610699108489765 \n",
      " 0.005\n",
      "33 / 70\n",
      "\n",
      " 1.1971798266355302 \n",
      " 0.0005653331746866552 \n",
      " 0.005\n",
      "34 / 70\n",
      "\n",
      " 1.1966554357480483 \n",
      " 0.000524390887481907 \n",
      " 0.005\n",
      "35 / 70\n",
      "\n",
      " 1.1961681964338475 \n",
      " 0.0004872393142008047 \n",
      " 0.005\n",
      "36 / 70\n",
      "\n",
      " 1.1957148765183203 \n",
      " 0.0004533199155272172 \n",
      " 0.005\n",
      "37 / 70\n",
      "\n",
      " 1.1952927458317442 \n",
      " 0.00042213068657614983 \n",
      " 0.005\n",
      "38 / 70\n",
      "\n",
      " 1.1948995333147379 \n",
      " 0.0003932125170063028 \n",
      " 0.005\n",
      "39 / 70\n",
      "\n",
      " 1.1945333939711629 \n",
      " 0.00036613934357498934 \n",
      " 0.005\n",
      "40 / 70\n",
      "\n",
      " 1.1941928820215484 \n",
      " 0.00034051194961448594 \n",
      " 0.005\n",
      "41 / 70\n",
      "\n",
      " 1.1938769266007279 \n",
      " 0.00031595542082052397 \n",
      " 0.005\n",
      "42 / 70\n",
      "\n",
      " 1.193584806322072 \n",
      " 0.00029212027865588297 \n",
      " 0.005\n",
      "43 / 70\n",
      "\n",
      " 1.1933161191542732 \n",
      " 0.00026868716779882007 \n",
      " 0.005\n",
      "44 / 70\n",
      "\n",
      " 1.1930707444873614 \n",
      " 0.00024537466691176846 \n",
      " 0.005\n",
      "45 / 70\n",
      "\n",
      " 1.1928487951310713 \n",
      " 0.00022194935629005208 \n",
      " 0.005\n",
      "46 / 70\n",
      "\n",
      " 1.1926505583472844 \n",
      " 0.00019823678378694254 \n",
      " 0.005\n",
      "47 / 70\n",
      "\n",
      " 1.1924764268012895 \n",
      " 0.00017413154599488223 \n",
      " 0.005\n",
      "48 / 70\n",
      "\n",
      " 1.1923268223130488 \n",
      " 0.000149604488240751 \n",
      " 0.005\n",
      "49 / 70\n",
      "\n",
      " 1.192202117153701 \n",
      " 0.00012470515934781545 \n",
      " 0.005\n",
      "50 / 70\n",
      "\n",
      " 1.192102558958321 \n",
      " 9.955819537998956e-05 \n",
      " 0.005\n",
      "51 / 70\n",
      "\n",
      " 1.1920282057526042 \n",
      " 7.435320571680393e-05 \n",
      " 0.005\n",
      "52 / 70\n",
      "\n",
      " 1.191978876928482 \n",
      " 4.932882412211903e-05 \n",
      " 0.005\n",
      "53 / 70\n",
      "\n",
      " 1.1919541243099714 \n",
      " 2.475261851064836e-05 \n",
      " 0.005\n",
      "54 / 70\n",
      "\n",
      " 1.1919532250414229 \n",
      " 8.992685485154084e-07 \n",
      " 0.005\n",
      "55 / 70\n",
      "\n",
      " 1.1919751953943625 \n",
      " -2.1970352939604254e-05 \n",
      " 0.005\n",
      "56 / 70\n",
      "\n",
      " 1.1920188222490946 \n",
      " -4.362685473213723e-05 \n",
      " 0.005\n",
      "57 / 70\n",
      "\n",
      " 1.1920827073759455 \n",
      " -6.38851268508489e-05 \n",
      " 0.005\n",
      "58 / 70\n",
      "\n",
      " 1.192165318921462 \n",
      " -8.261154551658656e-05 \n",
      " 0.005\n",
      "59 / 70\n",
      "\n",
      " 1.1922650446756107 \n",
      " -9.972575414862739e-05 \n",
      " 0.005\n",
      "60 / 70\n",
      "\n",
      " 1.1923802425541687 \n",
      " -0.00011519787855807095 \n",
      " 0.005\n",
      "61 / 70\n",
      "\n",
      " 1.1925092849845818 \n",
      " -0.00012904243041300667 \n",
      " 0.005\n",
      "62 / 70\n",
      "\n",
      " 1.192650595241556 \n",
      " -0.0001413102569742808 \n",
      " 0.005\n",
      "63 / 70\n",
      "\n",
      " 1.1928026750114862 \n",
      " -0.00015207976993014682 \n",
      " 0.005\n",
      "64 / 70\n",
      "\n",
      " 1.1929641234334334 \n",
      " -0.00016144842194720788 \n",
      " 0.005\n",
      "65 / 70\n",
      "\n",
      " 1.193133648521382 \n",
      " -0.00016952508794854104 \n",
      " 0.005\n",
      "66 / 70\n",
      "\n",
      " 1.1933100722320462 \n",
      " -0.0001764237106642863 \n",
      " 0.005\n",
      "67 / 70\n",
      "\n",
      " 1.1934923305622578 \n",
      " -0.000182258330211571 \n",
      " 0.005\n",
      "68 / 70\n",
      "\n",
      " 1.1936794700085969 \n",
      " -0.00018713944633907964 \n",
      " 0.005\n",
      "69 / 70\n",
      "\n",
      " 1.1938706415667646 \n",
      " -0.00019117155816772424 \n",
      " 0.005\n",
      "1.1938706415667646\n"
     ]
    }
   ],
   "execution_count": 446
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T20:15:16.266297Z",
     "start_time": "2025-09-27T20:15:16.259921Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\" during the test my best score was 1.127343 (didn't save the hyper parameter neither the initialisation of matrix) and i checked on internet i need biais to get better\"\"\"",
   "outputs": [],
   "execution_count": 314
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Making Recommendations\n",
    "\n",
    "The ultimate goal is to recommend movies! Now that we have our trained matrices $P$ and $Q$, we can predict the rating for *any* user-item pair, including those the user has not seen yet.\n",
    "\n",
    "The process for a given user `user_id`:\n",
    "1.  Get the user's latent vector $p_u$ from the trained matrix $P$.\n",
    "2.  Calculate the predicted ratings for all items by taking the dot product of $p_u$ and the entire item-feature matrix $Q^T$.\n",
    "3.  Create a list of movie titles and their predicted ratings.\n",
    "4.  Filter out movies the user has already seen.\n",
    "5.  Sort the remaining movies by their predicted rating in descending order.\n",
    "6.  Return the top N movies."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T21:03:25.532877Z",
     "start_time": "2025-09-27T21:03:25.520385Z"
    }
   },
   "source": [
    "def recommend_top_movies(user_id, P, Q, movie_titles_df, R_df, top_n=10):\n",
    "    \"\"\"\n",
    "    Recommends top N movies for a given user.\n",
    "\n",
    "    Args:\n",
    "        user_id (int): The ID of the user.\n",
    "        P (np.ndarray): The trained user-feature matrix.\n",
    "        Q (np.ndarray): The trained item-feature matrix.\n",
    "        movie_titles_df (pd.DataFrame): Dataframe with item_id and title.\n",
    "        R_df (pd.DataFrame): The original user-item matrix dataframe (for checking seen movies).\n",
    "        top_n (int): The number of movies to recommend.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A dataframe with the top N recommended movie titles and their predicted ratings.\n",
    "    \"\"\"\n",
    "\n",
    "    user_pos = R_df.index.get_loc(user_id) if user_id in R_df.index else int(user_id)\n",
    "    n_users, n_items = R_df.shape\n",
    "\n",
    "\n",
    "    if P.shape[0] == n_users and Q.shape[0] == n_items:\n",
    "        preds_vec = P[user_pos, :] @ Q.T\n",
    "    else:\n",
    "        preds_vec = Q[user_pos, :] @ P.T\n",
    "\n",
    "\n",
    "\n",
    "    preds = pd.Series(preds_vec, index=R_df.columns, name=\"pred_rating\")\n",
    "\n",
    "    # retirer les films déjà vus par l’utilisateur\n",
    "    seen_mask = R_df.loc[R_df.index[user_pos]] > 0\n",
    "    preds = preds[~seen_mask]\n",
    "\n",
    "    # joindre les titres (assurer le bon dtype pour la jointure)\n",
    "    mt = movie_titles_df.copy()\n",
    "    mt['item_id'] = mt['item_id'].astype(preds.index.dtype)\n",
    "\n",
    "    top = (\n",
    "        preds.sort_values(ascending=False)\n",
    "             .head(top_n)\n",
    "             .reset_index()\n",
    "             .rename(columns={'index': 'item_id'})\n",
    "             .merge(mt, on='item_id', how='left')\n",
    "             [['item_id', 'title', 'pred_rating']]\n",
    "    )\n",
    "    return top\n",
    "\n",
    "R_df = pd.DataFrame(R_train,index=np.arange(P.shape[0]),columns=np.arange(Q.shape[0]))\n",
    "\n",
    "\n",
    "movie_titles_df = pd.DataFrame({\"item_id\": R_df.columns,\"title\": [f\"Movie {i}\" for i in R_df.columns]})\n",
    "\n",
    "\n",
    "top10 = recommend_top_movies(user_id=42, P=P, Q=Q,\n",
    "                             movie_titles_df=movie_titles_df, R_df=R_df, top_n=10)\n",
    "\n",
    "top10\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   item_id       title  pred_rating\n",
       "0     1438  Movie 1438     4.711771\n",
       "1     1359  Movie 1359     4.567554\n",
       "2     1454  Movie 1454     4.422200\n",
       "3       63    Movie 63     4.398822\n",
       "4     1486  Movie 1486     4.388082\n",
       "5     1602  Movie 1602     4.299168\n",
       "6       21    Movie 21     4.265374\n",
       "7     1061  Movie 1061     4.260519\n",
       "8      250   Movie 250     4.224960\n",
       "9      171   Movie 171     4.221998"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>pred_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1438</td>\n",
       "      <td>Movie 1438</td>\n",
       "      <td>4.711771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1359</td>\n",
       "      <td>Movie 1359</td>\n",
       "      <td>4.567554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1454</td>\n",
       "      <td>Movie 1454</td>\n",
       "      <td>4.422200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>Movie 63</td>\n",
       "      <td>4.398822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1486</td>\n",
       "      <td>Movie 1486</td>\n",
       "      <td>4.388082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1602</td>\n",
       "      <td>Movie 1602</td>\n",
       "      <td>4.299168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>Movie 21</td>\n",
       "      <td>4.265374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1061</td>\n",
       "      <td>Movie 1061</td>\n",
       "      <td>4.260519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>250</td>\n",
       "      <td>Movie 250</td>\n",
       "      <td>4.224960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>171</td>\n",
       "      <td>Movie 171</td>\n",
       "      <td>4.221998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 453
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
